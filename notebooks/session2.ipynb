{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark for astronomy: hands-on session 2\n",
    "\n",
    "### Context\n",
    "\n",
    "Welcome to the series of notebooks on Apache Spark! The main goal of this series is to get familiar with Apache Spark, and in particular its Python API called PySpark in a context of the astronomy. In this second notebook, we will learn on concrete examples how to interface and play with popular scientific libraries (Numpy, Pandas, ...).\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Interfacing popular Python scientific libraries with Apache Spark\n",
    "- Developing your own modules for Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this series of exercises, we will use the same dataset as in the first session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a Spark DataFrame\n",
    "df = spark.read.format(\"parquet\").load(\"../data/clusters.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined functions and column creation\n",
    "\n",
    "Similarly to `map` and `mapPartitions`, you would like to define your own functions but this time to create new DataFrame columns. In python, the efficient way of doing this is via \"Pandas User Defined Functions\" (vectorized functions). \n",
    "\n",
    "**Exercise (£):** Use pandas UDF to compute the distance of each row to the center (x, y, z) = (0, 0, 0), and store the result in a new Dataframe column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import DoubleType\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf('double', PandasUDFType.SCALAR)\n",
    "def distance_mod(cols):\n",
    "    \n",
    "    x = cols.select('x')\n",
    "    y = cols.select('y')\n",
    "    z = cols.select('z')\n",
    "    \n",
    "    r_sq = x*x + y*y + z*z\n",
    "    return pd.Series(np.sqrt(r_sq))\n",
    "    \n",
    "\n",
    "df.withColumn(\"distance\", distance_mod(df.select('x', 'y', 'z')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+---+------------------+\n",
      "|                  x|                  y|                 z| id|          distance|\n",
      "+-------------------+-------------------+------------------+---+------------------+\n",
      "|-1.4076402686194887|  6.673344773733206| 8.208460943517498|  2|10.672104415540714|\n",
      "| 0.6498424376672443|  3.744291410605022|1.0917784706793445|  0|3.9539845207540685|\n",
      "| 1.3036201950328201|-2.0809475280266656| 4.704460741202294|  1|5.3067616389669645|\n",
      "|-1.3741641126376476|  4.791424573067701| 2.562770404033503|  0| 5.604807631993114|\n",
      "| 0.3454761504864363| -2.481008091382492|2.3088066072973583|  1|3.4066615432062313|\n",
      "+-------------------+-------------------+------------------+---+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('double', PandasUDFType.SCALAR)\n",
    "def distance_mod(x, y, z):\n",
    "    \n",
    "    r_sq = x*x + y*y + z*z\n",
    "    return pd.Series(np.sqrt(r_sq))\n",
    "    \n",
    "    \n",
    "df.withColumn(\n",
    "    \"distance\", \n",
    "    distance_mod(\n",
    "        col(\"x\"), \n",
    "        col(\"y\"), \n",
    "        col(\"z\")\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (£££):** As in session 1, find the barycentre of each clusters in the dataset but this time using aggregation and user defined function (hint: look for `PandasUDFType.GROUPED_MAP`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+---+\n",
      "|                  x|                  y|                 z| id|\n",
      "+-------------------+-------------------+------------------+---+\n",
      "| 0.9084311322436593|-1.5335608883132903| 2.926201255363395|  1|\n",
      "|-1.2364938227997018| 7.7837163227456205| 9.292937669035544|  2|\n",
      "|  1.001314312562809|  4.250879907797302|2.0216900721305446|  0|\n",
      "+-------------------+-------------------+------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(df.schema, PandasUDFType.GROUPED_MAP)\n",
    "def barycentre(dataframe: pd.DataFrameta):\n",
    "    \n",
    "    mean = dataframe.mean()\n",
    "    # This is just to reconstruct a Pandas DataFrames with the result\n",
    "    # i: column name, j: mean value [list of x, y, z]\n",
    "    out = {i : [j] for i, j in zip(mean.keys(), mean.values)}\n",
    "    return pd.DataFrame(out)\n",
    "    \n",
    "df.groupBy(\"id\").apply(barycentre).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
